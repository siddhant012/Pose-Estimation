How this works?
1.It works by creating a pose encoding for a given pose.Similar poses will have similar pose encodings and different poses will have dissimilar pose encodings. 
2.Poses are recorded and displayed in real time and pose encodings are saved in json format in the directory named webcam encodings.
3.These encodings can be loaded and can be used to compare with other pose encodings (of some other person) using the load_encoding() , get_simmilarity() and other functions in the file helper_funcs.py


How to use?
1.Clone the repository.
2.Download the required files in the directories named coco and mpi (download links and other details in coco/readme.txt and mpi/readme.txt)
3.Specify the required values in the info.py
4.Run the run.py file.
5.Webcam will open and start recording and displaying poses.The poses are recorded as encodings in json format for each frame in the directory named webcam encodings.
6.You can also run the demonstration.py file to get a demonstration of how the encoding and simmilarity of pose encodings work.

Requirements : cv2.__version__==4.3.0

(Optional)
Samples for demontration
1.For the purpose of demonstration , there are two sample videos in the directory named samples (far.mp4 and near.mp4) which are dance tutorials of a person from different distances.
2.There are sub folders within the samples directory from 30 to 48 , each one denoting the corresponding frame within these sample video files (for ex: 30 denote the 30th frame  , only some frames have been uploaded because github has an upload limit of 100 files).
3.Each such sub folder has 5 files :
a. far_encoding.json  : encoding of the corresponding frame in far.mp4
b. near_encoding.json : encoding of the corresponding frame in near.mp4
c. far_frame.jpg      : estimated pose of the corresponding frame in far.mp4
d. near_frame.jpg     : estimated pose of the corresponding frame in near.mp4
e. simmilarity.txt    : A measure of similarity between the two poses.
Different frames and their simmilarity measure can be viewed to get an idea of how good the model is performing.
The samples have been generated by running the generate_samples.py file .
