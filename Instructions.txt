How this works?
1.It works by creating a pose encoding for a given pose.Similar poses will have similar pose encodings and different poses will have dissimilar pose encodings. 
2.Poses are recorded and displayed in real time and pose encodings are saved in json format in the directory named webcam encodings.
3.These encodings can be loaded and compared to other pose encodings (of some other person) using the load_encoding() and get_simmilarity() functions in the file compare.py


How to use?
1.Clone the repository.
2.Specify the required values in the info.py
3.Run the run.py file.
4.Webcam will open and start recording and displaying poses.The poses are recorded as encodings in json format for each frame in the directory named webcam encodings.  


Samples for demontration
1.For the purpose of demonstration , there are two sample videos in the directory named samples (far.mp4 and near.mp4) which are dance tutorials of a person from different distances.
2.There are sub folders within the samples directory from 1 to 700 , each one denoting a frame within these sample video files.
3.Each directory has 5 files :
a. far_encoding.json  : encoding of the corresponding frame in far.mp4
b. near_encoding.json : encoding of the corresponding frame in near.mp4
c. far_frame.jpg      : estimated pose of the corresponding frame in far.mp4
d. near_frame.jpg     : estimated pose of the corresponding frame in near.mp4
e. simmilarity.txt    : A measure of similarity between the two poses.

Different frames and their simmilarity measure can be viewed to get an idea of how good the model is performing.
The samples have been generated by running the generate_samples.py file
